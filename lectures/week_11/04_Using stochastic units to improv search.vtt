WEBVTT

1
00:00:00.000 --> 00:00:06.311
In this video, I'm going to explain how
adding noise can help systems escape from

2
00:00:06.311 --> 00:00:10.362
local minima.
And, I'm going to show what you have to do

3
00:00:10.362 --> 00:00:15.427
to the units in Hopfield net to add noise
in the appropriate way.

4
00:00:15.427 --> 00:00:21.816
I'm not going to introduce the idea that
we confined better minima by using noise.

5
00:00:21.816 --> 00:00:27.971
So, Hopfield net always makes decisions
that reduce the energy, or if it doesn't

6
00:00:27.971 --> 00:00:31.400
state of the unit, the energy stays the
same.

7
00:00:31.400 --> 00:00:35.199
This makes it impossible to climb out of a
local minimum.

8
00:00:35.199 --> 00:00:39.998
So, if you look at the landscape here.
If we get into the local minimum A,

9
00:00:39.998 --> 00:00:45.064
there's no way we're going to get over the
energy barrier to get to the better

10
00:00:45.064 --> 00:00:48.197
minimum B because we can't go uphill in
energy.

11
00:00:48.197 --> 00:00:53.530
If we add random noise, we can escape from
poor minima, especially minima that is

12
00:00:53.530 --> 00:00:58.130
shallow, that is, ones that don't have big
energy barriers around them.

13
00:00:58.130 --> 00:01:03.342
It turns out, rather than using a fixed
noise level, the most effective strategy

14
00:01:03.342 --> 00:01:08.290
is to start with a lot of noise which
allows you to explore the space on a

15
00:01:08.290 --> 00:01:13.767
coarse scale and find the generally good
regions of the space, and then to decrease

16
00:01:13.767 --> 00:01:17.329
the noise level.
With a lot of noise, you can cross big

17
00:01:17.329 --> 00:01:20.694
barriers.
As you decrease the noise level, you start

18
00:01:20.694 --> 00:01:26.702
concentrating on the best nearby minima.
If you slowly reduce the noise, so the

19
00:01:26.702 --> 00:01:31.680
system ends up in a deep minimum, that's
called simulated annealing.

20
00:01:31.680 --> 00:01:37.178
And this ideal was, propogated by
Kirkpatrick at around the same time as

21
00:01:37.178 --> 00:01:42.375
Hopfield nets were proposed.
So, the reason for simulated annealing is

22
00:01:42.375 --> 00:01:48.174
because the temperature, in a physical
system, or in a simulated system with a

23
00:01:48.174 --> 00:01:52.311
energy function,
Affects the transition probabilities.

24
00:01:52.311 --> 00:01:58.571
So, in a high temperature system, the
probability of going uphill from B to A is

25
00:01:58.571 --> 00:02:03.088
lower than the probability of going
downhill from A to B.

26
00:02:03.088 --> 00:02:07.362
But it's not much lower.
In effect, the temperature flattens the

27
00:02:07.362 --> 00:02:11.741
energy landscape, and so the little black
dots are meant to be particles.

28
00:02:11.741 --> 00:02:16.606
And what we are imagining is particles
moving about according to the transition

29
00:02:16.606 --> 00:02:20.803
probabilities that you get with an energy
function and a temperature.

30
00:02:20.803 --> 00:02:25.304
And this might be a typical distribution
if you're on the system of high

31
00:02:25.304 --> 00:02:30.170
temperature where it's easier to cross
barriers, but it's also hard to stay in a

32
00:02:30.170 --> 00:02:34.610
deep minimum once you've got that.
If you are in the system of much lower

33
00:02:34.610 --> 00:02:38.876
temperature,
Then your probability of crossing barriers

34
00:02:38.876 --> 00:02:42.640
gets much smaller but your ratio gets much
better.

35
00:02:42.900 --> 00:02:48.430
So, the ratio of the probability of going
from A to B versus the probability of

36
00:02:48.430 --> 00:02:52.840
going from B to A is much better in the
low temperature system.

37
00:02:53.100 --> 00:02:58.879
And so, if we run it long enough, we would
expect all of the particles to end up in

38
00:02:58.879 --> 00:03:01.922
B.
But if we just run it for a long time at

39
00:03:01.922 --> 00:03:06.322
low temperature, it will take a very long
time for particles to escape from A.

40
00:03:06.322 --> 00:03:11.065
And it turns out a good compromise is to
start at a high temperature and gradually

41
00:03:11.065 --> 00:03:16.201
reduce the temperature.
The way we get noise in to Hopfield net is

42
00:03:16.201 --> 00:03:22.366
to replace the binary threshold units by
binary stochastic units and make biased

43
00:03:22.366 --> 00:03:27.184
random decisions.
And the amount of noise is controlled by

44
00:03:27.184 --> 00:03:31.827
something called temperature,
Which you'll see in a minute in the

45
00:03:31.827 --> 00:03:34.948
equation.
Raising the noise level is equivalent to

46
00:03:34.948 --> 00:03:38.320
decreasing all the energy gaps between
configurations.

47
00:03:39.500 --> 00:03:47.290
So, this is our normal logistic equation.
But with the energy gap scaled by a

48
00:03:47.290 --> 00:03:53.514
temperature.
If the temperature is very high, that

49
00:03:53.514 --> 00:03:58.969
exponent will be roughly zero, so the
right hand side will be one over one plus

50
00:03:58.969 --> 00:04:03.871
one. And so, the probability of the unit
turning on will be about a half.

51
00:04:03.871 --> 00:04:07.945
It'll be in it's on and off states, more
or less equally off.

52
00:04:09.080 --> 00:04:15.645
As we lower the temperature,
Depending on the sign of delta E, the unit

53
00:04:15.645 --> 00:04:21.757
will become either more and more firmly on
and more and more firmly off.

54
00:04:21.757 --> 00:04:27.530
At zero temperature, which is what we're
be using in a Hopfield net,

55
00:04:27.530 --> 00:04:34.066
Then the sign of delta E determines
whether the right hand side goes to zero

56
00:04:34.066 --> 00:04:38.479
or goes to one.
But, with T zero, it will either be zero

57
00:04:38.479 --> 00:04:42.344
or one on the right hand side.
And so, the unit will behave

58
00:04:42.344 --> 00:04:45.877
deterministically and that's a binary
threshold unit.

59
00:04:45.877 --> 00:04:50.476
It will always adopt whatever of the two
states is the lowest energy.

60
00:04:50.476 --> 00:04:55.874
So, the energy gap we saw on a previous
slide, and it's just the difference in the

61
00:04:55.874 --> 00:05:01.140
energy of the whole system depending on
whether unit I is off, or the unit I is

62
00:05:01.140 --> 00:05:04.612
on.
Although simulated annealing is a very

63
00:05:04.612 --> 00:05:09.909
powerful method for improving searches
that get stuck in local optima, and

64
00:05:09.909 --> 00:05:15.708
although it was influential in leading
Terry Sejnowski and I to the ideas behind

65
00:05:15.708 --> 00:05:21.435
Boltzmann machines, it's actually a big
distraction from understanding Boltzmann

66
00:05:21.435 --> 00:05:25.585
machines.
So, I'm not going to talk about it anymore

67
00:05:25.585 --> 00:05:29.139
in this course even though it's a very
interesting idea.

68
00:05:29.139 --> 00:05:33.835
And, from now on, I'm going to use binary
stochastic units that have a temperature

69
00:05:33.835 --> 00:05:37.043
of one.
That is, it's the standard logistic

70
00:05:37.043 --> 00:05:41.885
function in the energy gap.
So, one concept that you need to

71
00:05:41.885 --> 00:05:47.526
understand in order to understand the
learning procedure for both the machines,

72
00:05:47.526 --> 00:05:53.052
is the concept of thermal equilibrium.
And because we're setting the temperature

73
00:05:53.052 --> 00:05:57.120
to one, this the concept of thermal
equilibrium at a fix temperature.

74
00:05:57.120 --> 00:06:01.845
It's a difficult concept. Most people
think that it means the system is settled

75
00:06:01.845 --> 00:06:06.631
down and isn't changing anymore. That's
normally what equilibrium means. But it's

76
00:06:06.631 --> 00:06:10.280
not the states of the individual units
that are settled down.

77
00:06:10.920 --> 00:06:16.411
The individual units are still rattling
around at thermal equilibrium, and less

78
00:06:16.411 --> 00:06:22.111
temperature zero. The thing that settles
down is the probability distribution over

79
00:06:22.111 --> 00:06:27.672
configurations. That's a difficult concept
the first time you meet it, and so I'm

80
00:06:27.672 --> 00:06:32.520
going to give you an example.
The probability distribution settles to a

81
00:06:32.520 --> 00:06:36.145
particular distribution called the
Stationary Distribution.

82
00:06:36.145 --> 00:06:41.000
The stationary distribution is determined
by the energy function of the system.

83
00:06:41.260 --> 00:06:45.550
And, in fact, in the stationary
distribution, the probability of any

84
00:06:45.550 --> 00:06:49.580
configuration is proportional to each of
the minus its energy.

85
00:06:50.000 --> 00:06:55.405
A nice intuitive way to think about
thermal equilibrium is to imagine a huge

86
00:06:55.405 --> 00:07:00.810
ensemble of identical systems that all
have exactly the same energy function.

87
00:07:00.810 --> 00:07:06.356
So, imagine a very large number of
stochastic Hopfield nets all with the same

88
00:07:06.356 --> 00:07:09.725
weights.
Now, in that huge ensemble, we can define

89
00:07:09.725 --> 00:07:15.411
the probability of configuration as the
fraction of the systems that are in that

90
00:07:15.411 --> 00:07:19.343
configuration.
So, now we can understand what's happening

91
00:07:19.343 --> 00:07:25.452
as we approach thermal equilibrium.
We can start with any distribution we like

92
00:07:25.452 --> 00:07:29.501
over all these identical systems. We could
make them all, be in the same

93
00:07:29.501 --> 00:07:33.550
configuration. So, that's the distribution
with a property of one on one

94
00:07:33.550 --> 00:07:37.941
configuration, and zero on everything
else. Or we could start them off, with an

95
00:07:37.941 --> 00:07:41.078
equal number of systems in each possible
configuration.

96
00:07:41.078 --> 00:07:45.514
So that's a uniform distribution.
And then, we're going to keep applying our

97
00:07:45.514 --> 00:07:49.247
stochastic update rule.
Which, in the case of a stochastic

98
00:07:49.247 --> 00:07:53.373
Hopfield net would mean,
You pick a unit, and you look at its

99
00:07:53.373 --> 00:07:56.713
energy gap.
And you make a random decision based on

100
00:07:56.713 --> 00:08:00.578
that energy gap about whether to turn it
on or turn it off.

101
00:08:00.578 --> 00:08:03.460
Then, you go and pick another unit, and so
on.

102
00:08:03.880 --> 00:08:10.001
We keep applying that stochastic rule.
And after we've run systems stochastically

103
00:08:10.001 --> 00:08:13.499
in this way,
We may eventually reach a situation where

104
00:08:13.499 --> 00:08:17.840
the fraction of the systems in each
configuration remains constant.

105
00:08:17.840 --> 00:08:22.051
In fact, that's what will happen if we
have symmetric connections.

106
00:08:22.051 --> 00:08:26.975
That's the stationary distribution that
physicists call thermal equilibrium.

107
00:08:26.975 --> 00:08:30.214
Any given system keeps changing its
configuration.

108
00:08:30.214 --> 00:08:34.296
We apply the update rule,
And the states of its units will keep

109
00:08:34.296 --> 00:08:39.226
flipping between zero and one.
But, the fraction of systems in any

110
00:08:39.226 --> 00:08:45.098
particular configuration doesn't change.
And that's because we have many, many more

111
00:08:45.098 --> 00:08:51.000
systems than we have configurations.
So, here's an analogy kust to help with

112
00:08:51.000 --> 00:08:55.443
the concept.
Imagine a very large casino in Las Vegas

113
00:08:55.443 --> 00:09:00.416
with lots of card dealers. And, in fact,
we have many more than 52 factorial card

114
00:09:00.416 --> 00:09:05.848
dealers. We start with all the card packs
in the standard order that they come from

115
00:09:05.848 --> 00:09:11.149
the manufacturer. Let's suppose that has
the ace of spades, and the king of spades,

116
00:09:11.149 --> 00:09:15.688
and the queen of spades.
And then, the dealers all start shuffling.

117
00:09:15.688 --> 00:09:20.930
And they do random shuffles, they don't do
fancy shuffles that bring them back to the

118
00:09:20.930 --> 00:09:24.569
same order again.
After a few shuffles, there's still a good

119
00:09:24.569 --> 00:09:29.502
chance that the king of spades will be
next to the queen of spades in any given

120
00:09:29.502 --> 00:09:32.401
pack.
So, the packs have not yet forgotten where

121
00:09:32.401 --> 00:09:35.731
they started.
Their initial order is still influencing

122
00:09:35.731 --> 00:09:39.184
their current order.
If we keep shuffling, eventually the

123
00:09:39.184 --> 00:09:43.622
initial order will be irrelevant.
The packs will have forgotten where they

124
00:09:43.622 --> 00:09:46.377
started.
And, in fact, in this example, there will

125
00:09:46.377 --> 00:09:50.596
be an equal number of packs in each of the
52 factorial possible orders.

126
00:09:50.596 --> 00:09:53.410
Once this has happened, if we carry on
shuffling,

127
00:09:53.410 --> 00:09:58.126
There'll still be an equal number of packs
in each of the 52 factorial orders.

128
00:09:58.126 --> 00:10:02.419
That's why it's called equilibrium.
It's because the fraction in any one

129
00:10:02.419 --> 00:10:06.531
configuration doesn't change,
Even though the individual systems are

130
00:10:06.531 --> 00:10:09.917
still changing.
The thing that's wrong with this analogy

131
00:10:09.917 --> 00:10:14.634
is that once we've each equilibrium here,
all configurations have equal energy.

132
00:10:14.634 --> 00:10:17.173
And so, they all have the same
probability.

133
00:10:17.173 --> 00:10:21.708
In general, we're interested in reaching
equilibrium for systems where some

134
00:10:21.708 --> 00:10:24.430
configurations have lower energy than
others.